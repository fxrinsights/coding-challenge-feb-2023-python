#+TITLE: FXR Python coding challenge - february 2023
#+BIND: org-export-use-babel nil
#+AUTHOR: July
#+EMAIL: <july@fxr-insights.com>
#+DATE: February, 2023
#+LATEX: \setlength\parindent{0pt}
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage[margin=1.2in]{geometry}
#+LATEX_HEADER: \usepackage{mathpazo}
#+LATEX_HEADER: \usepackage{adjustbox}
#+LATEX_HEADER_EXTRA:  \usepackage{mdframed}
#+LATEX_HEADER_EXTRA: \BeforeBeginEnvironment{minted}{\begin{mdframed}}
#+LATEX_HEADER_EXTRA: \AfterEndEnvironment{minted}{\end{mdframed}}
#+LATEX_HEADER_EXTRA: \BeforeBeginEnvironment{tabular}{\begin{adjustbox}{center}}
#+LATEX_HEADER_EXTRA: \AfterEndEnvironment{tabular}{\end{adjustbox}}
#+MACRO: NEWLINE @@latex:\\@@ @@html:<br>@@
#+PROPERTY: header-args :exports both :session fxr-coding-challenge-feb-2023 :cache :results value
#+OPTIONS: ^:nil
#+LATEX_COMPILER: pdflatex

* introduction

this coding challenge is about rewriting an existing implementation with the
goal of improving performance and code structure.

in our codebase, we have the need for the following functionality: we need to
format and parse strings which are composed out of multiple components. we call
these =namers=. formatting means that we take the components (in a dictionary)
and put them together into a string. parsing means that we take a string and
extract the the components from it.

* example: DTIDNamer

for instance, we do this for a =dtid=, which is a unique identifier for a
document table (one table inside one document). a dtid is the combination of
three components, separated by a =/=:
1. the document id
2. the type of table
3. the tnum (i.e., this is the ith table of this type in this document)

so for the =dtid=, formatting would mean:

#+BEGIN_SRC python
DTIDNamer({"document_id": "1234", "tabletype": "some-org_2", "tnum": 3}).name
# => "1234/some-org_2/3"
#+END_SRC

and parsing would mean:

#+BEGIN_SRC python
DTIDNamer("1234/some-org_2/3").components
# => {"document_id": "1234", "tabletype": "some-org_2", "tnum": 3}
#+END_SRC

* problems with the current implementation

we have an implementation, but we are not so happy with it, because it's pretty
slow.

** no vectorized implementation

we actually mainly use these namers on sequences of data (pandas DataFrames and
Series). we have class methods to format a =pd.DataFrame= of components
(=format_components_df=), and parse a =pd.Series= of names
(=parse_names_series=). however, under the hood, they create a namer instance
for every row, because the actual parsing and formatting is not vectorized. if
you inspect those functions, you can see that they both use pandas'
=.apply=. we would instead like to use vectorized pandas methods, like
=.str.split= and =.str.join=.

keep in mind that different namers might have different parsing and formatting
strategies (e.g. not just splitting and joining using a certain separator), so
namers are responsible for defining that strategy (but the strategy could be
bundled in a class).

** a slow validation library

the validation library we are using, [[https://github.com/keleshev/schema/][schema]], is very slow, and *does not*
support vectorized validation.

we use this validation for two things:
- if you try to initialize the class with a dictionary which is incomplete or
  whose values have the wrong datatypes, an error is raised.
- the =Use(str)= for the =tnum= attribute ensures that the =.validate= converts
  an int to string, and it's nice to support that someone can pass an int as a
  =tnum= (read more about this in the [[https://github.com/keleshev/schema#readme][README of the schema library]]).

since this library does not support vectorized validation, and it's too slow to
apply element-wise validation with it, we need an alternative way to validate
(and if possible, do that int to str type conversion).

we use schema in other parts of the code, and we are considering replacing it
with [[https://horejsek.github.io/python-fastjsonschema/][fastjsonschema]] or [[https://docs.pydantic.dev/][pydantic]], so you might want to look into it. (or decide
that a full library is not necessary for this part of the code; but flexible
validation should remain easy to implement).

** inheritance pattern

in addition, the current implementation uses the inheritance pattern, and we
prefer composition over inheritance. perhaps, there's a bit too much logic
bundled in the BaseNamer class.

you have freedom here to choose how much you want to invest in reorganising the
code. it would be nice to see the implementation less clunky and more modular,
but don't spend too much time on it.

* the challenge

so we want you to comprehensively adapt the existing implementation to natively
support large volumes of data (which also entails alternative validation).

we want you to make this work specifically for =dtid='s, but it should be
generalizable to work for any namer, even ones with different formatting and
parsing strategies than just concatenating strings with a separator.

to give you a pointer in the right direction: we would think about initializing
a general Namer class with an instance of a (currently not existing) class
which is responsible for implementing formatting and parsing, for both
vectorized and unvectorized cases. so, perhaps something like:

#+BEGIN_SRC python
DTID_NAMER = Namer(some_parsing_and_formatting_strategy, **other_attributes)
#+END_SRC

note that DTID_NAMER wouldn't be an initializable class, but instead would have
methods to immediately format and parse both individual values and
dataframes/series.

that's just a suggestion, feel free to do whatever you think is best.

** writing tests

we haven't included the unittests for this implementation, so we strongly
recommend that the first thing you do is to write some [[https://docs.python.org/3/library/unittest.html][unittests]] for the
existing implementation, making sure you cover all the cases / methods (so:
parsing a string, formatting a dict, parsing a series, and formatting a
dataframe, as well as negative cases where you pass incomplete input).

once you have the unittests, you can start writing a new implementation, using
the unittests to test that your new implementation works in the same way.

** making it work for another namer

we've also included another namer, which has a bit of a different
functionality. it is not necessary to fully reimplement it (although that would
definitely be awesome), but you should comment about how your new
implementation would support it on a high level.

** questions, etc.

if you have any questions, let us know! (this is our first time creating a
coding challenge, so we hope it's clear enough.) you can reach July by emailing
=july @ [our domain name]=.

good luck!

* getting started

** create a private fork

please create a *private fork* by following the steps below. don't create a
public fork, because other applicants might be able to read your solution. if
you are unable to create a private fork, clone the repo, commit your solution,
and send us a zip file of your solution.

1. go to https://github.com/new/import
2. enter the url of this repo, and create a new repository under your account
   with visibility set to private.
3. invite the following github users as collaborators: =jpjagt= and
   =paulodder=.

** setting up the environment

you can install the dependencies with:

#+BEGIN_SRC python
cd path/to/cloned/repo
pip install -r requirements.txt
#+END_SRC

(tip: use a virtualenv!)

then, you can start working on the refactor. push your changes to github. once
you're done, please send us a message (:
